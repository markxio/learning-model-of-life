apiVersion: batch/v1
kind: Job
metadata:
  generateName: $USER-job-
  labels:
    eidf/user: $USER
    kueue.x-k8s.io/queue-name: $INFK8S_QUEUE_NAME
    kueue.x-k8s.io/priority-class: batch-workload-priority
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        eidf/user: $USER
    spec:
      restartPolicy: Never
      containers:
      - name: huggingface
        image: huggingface/transformers-pytorch-gpu:latest 
        imagePullPolicy: IfNotPresent
        workingDir: "/workspace"
        command: ["/bin/bash", "./run.sh"]
        env:
          - name: MY_USERNAME
            value: $USER
          - name: MY_EXPERIMENT 
            value: experiment1
        resources:
           limits:
            nvidia.com/gpu: 0
            cpu: 2
            memory: 4Gi
        volumeMounts:
          - name: workspace
            mountPath: /workspace
            readOnly: true
          - name: writeable
            mountPath: /workspace/writeable
          - name: publicdata
            mountPath: /public
            readOnly: true
      # nodeSelector:
      #  nvidia.com/gpu.product: NVIDIA-A100-SXM4-40GB
      volumes:
        - name: workspace
          nfs:
            server: $INFK8S_NFS_SERVER_IP
            path: $WORKING_DIR
        - name: writeable
          persistentVolumeClaim:
             claimName: $MY_PVC
        - name: publicdata
          nfs:
            server: $INFK8S_NFS_SERVER_IP
            path: /public

